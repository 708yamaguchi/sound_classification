<launch>
  <arg name="microphone_name" default="default"/> <!-- default microphone on thinkpad T460s -->
  <arg name="length" default="512"/> <!-- the number of sampling data in fft -->
  <arg name="rate" default="44100"/> <!-- sampling rate of microphone -->
  <arg name="cutoff_rate" default="8000"/> <!-- cutoff the high frequency data from fft result -->
  <arg name="hit_volume_threshold" default="0.01"/> <!-- volume threshold to detect sound -->
  <arg name="time_to_listen" default="1.0"/> <!-- time to publish spectrogram (= spectrogram publishing rate), not length of window function) -->
  <arg name="target_class" default="table"/> <!-- target class of saved spectrogram -->
  <arg name="classification" default="false"/> <!-- online sound classification on ROS -->
  <arg name="rqt" default="false"/> <!-- visualize spectrogram, object class and camera image on rqt -->

  <!-- publish sound topics from microphone -->
  <include file="$(find sound_classification)/launch/microphone.launch" >
    <!-- frequency resolution of fft: $(arg rate) / $(arg length) -->
    <arg name="microphone_name" value="$(arg microphone_name)"/>
    <arg name="length" value="$(arg length)"/>
    <arg name="rate" value="$(arg rate)"/>
    <arg name="cutoff_rate" value="$(arg cutoff_rate)"/>
    <arg name="hit_volume_threshold" value="$(arg hit_volume_threshold)"/>
    <arg name="time_to_listen" value="$(arg time_to_listen)"/>
    <arg name="classification" value="$(arg classification)"/>
    <arg name="rqt" value="$(arg rqt)"/>
  </include>

  <!-- save spectrogram in train/original_spectrogram -->
  <node pkg="sound_classification" name="save_spectrogram" type="save_spectrogram.py" output="screen">
    <param name="target_class" value="$(arg target_class)"/>
  </node>

</launch>
